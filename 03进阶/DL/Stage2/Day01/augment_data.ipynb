{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbmjOSNGRc1a"
      },
      "source": [
        "[torchvision.transforms 文档](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwMhRufaRgQF"
      },
      "source": [
        "# Torchvision 图像分类数据增强\n",
        "\n",
        "支持常见的计算机视觉转换、变换。可用于转换或增强数据，以训练或推理不同的任务（图像分类、检测、分割、视频分类）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FbarP25QT7lu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "# 定义图像的高度和宽度\n",
        "H, W = 32, 32\n",
        "\n",
        "# 创建一个随机的 RGB 图像张量，大小为 3x32x32，数据类型为 uint8\n",
        "# 红、绿、蓝通道，每个像素值在 0 到 255 之间随机生成\n",
        "img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)\n",
        "\n",
        "# 定义图像变换组合\n",
        "# 使用 v2.Compose 将多个变换操作串联在一起\n",
        "transforms = v2.Compose([\n",
        "    # 随机裁剪并缩放图像到指定大小 (224x224)\n",
        "    # RandomResizedCrop 会在随机的位置裁剪图像的一部分，然后将其缩放到指定大小\n",
        "    # antialias=True 表示在缩放时使用抗锯齿功能，减少图像失真\n",
        "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
        "\n",
        "    # 随机水平翻转图像\n",
        "    # p=0.5 表示翻转的概率为 50%，可以增强数据的多样性\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "    # 将张量的数据类型转换为 float32\n",
        "    # scale=True 表示对像素值进行线性缩放，将其从 [0, 255] 的范围归一化到 [0, 1] 的范围\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "\n",
        "    # 对图像进行标准化（归一化）操作\n",
        "    # 使用预定义的均值和标准差，通常是针对 ImageNet 数据集预训练模型的值\n",
        "    # mean=[0.485, 0.456, 0.406] 分别对应 RGB 通道的均值\n",
        "    # std=[0.229, 0.224, 0.225] 分别对应 RGB 通道的标准差\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 应用变换组合到输入图像\n",
        "# 将变换后的图像存储到变量 img 中\n",
        "img = transforms(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_8O06euPWNvf"
      },
      "outputs": [],
      "source": [
        "# 检测（复用之前的导入和变换）\n",
        "from torchvision import tv_tensors\n",
        "\n",
        "# 创建一个随机的 RGB 图像张量，大小为 3x32x32，数据类型为 uint8\n",
        "# 红、绿、蓝通道，每个像素值在 0 到 255 之间随机生成\n",
        "img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)\n",
        "\n",
        "# 创建随机的边界框坐标\n",
        "# randint 生成 0 到 H // 2 之间的随机整数，size=(3, 4) 表示生成 3 个边界框，每个边界框有 4 个坐标\n",
        "boxes = torch.randint(0, H // 2, size=(3, 4))\n",
        "# 调整边界框坐标，确保它们代表左上角和右下角的坐标 (XYXY 格式)\n",
        "boxes[:, 2:] += boxes[:, :2]\n",
        "# 将边界框坐标转换为 tv_tensors.BoundingBoxes 对象\n",
        "# format=\"XYXY\" 指定边界框格式为 XYXY，canvas_size=(H, W) 指定图像尺寸\n",
        "boxes = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=(H, W))\n",
        "\n",
        "# 应用相同的变换到图像和边界框\n",
        "# transforms 是之前定义的图像变换组合\n",
        "img, boxes = transforms(img, boxes)\n",
        "\n",
        "# 可以传递任意数据结构，例如字典\n",
        "# 创建一个字典，包含 \"image\" 和 \"boxes\" 键，分别存储图像和边界框\n",
        "# 将字典传递给 transforms，应用相同的变换\n",
        "output_dict = transforms({\"image\": img, \"boxes\": boxes})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqT_7UBCW_iZ"
      },
      "source": [
        "[v2 API](https://pytorch.org/vision/stable/transforms.html#v2-api-ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDo-23woXZ0P"
      },
      "source": [
        "* 上周的MNIST结果为例\n",
        "\n",
        "使用 `torchvision.transforms` 实现数据增强，并记录效果\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N88uobcfXZmf",
        "outputId": "455e1f0f-1bc4-461b-bfed-d9d117765907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.3956\n",
            "Epoch [2/10], Loss: 0.1610\n",
            "Epoch [3/10], Loss: 0.1103\n",
            "Epoch [4/10], Loss: 0.0843\n",
            "Epoch [5/10], Loss: 0.0663\n",
            "Epoch [6/10], Loss: 0.0512\n",
            "Epoch [7/10], Loss: 0.0423\n",
            "Epoch [8/10], Loss: 0.0330\n",
            "Epoch [9/10], Loss: 0.0287\n",
            "Epoch [10/10], Loss: 0.0218\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "'''\n",
        "当前模型是一个简单的全连接网络，\n",
        "'''\n",
        "# Load MNIST data from local CSV files\n",
        "train_data = pd.read_csv('./data/train.csv')\n",
        "test_data = pd.read_csv('./data/test.csv')\n",
        "\n",
        "# Prepare the data\n",
        "train_images = train_data.iloc[:, 1:].values.reshape(-1, 28, 28) / 255.0\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_images = test_data.values.reshape(-1, 28, 28) / 255.0\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_images = torch.tensor(train_images, dtype=torch.float32).unsqueeze(1)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_images = torch.tensor(test_images, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_images, torch.zeros(test_images.size(0), dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "model.eval()\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for data, _ in test_loader:\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predicted_labels.extend(predicted.numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqWy3gdKafkE"
      },
      "source": [
        "## 数据增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stXvznSDXG97",
        "outputId": "c3725635-2e08-4f97-bc03-956dbeb65bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 1.0481\n",
            "Epoch [2/10], Loss: 0.7296\n",
            "Epoch [3/10], Loss: 0.6267\n",
            "Epoch [4/10], Loss: 0.5442\n",
            "Epoch [5/10], Loss: 0.4720\n",
            "Epoch [6/10], Loss: 0.4039\n",
            "Epoch [7/10], Loss: 0.3428\n",
            "Epoch [8/10], Loss: 0.2884\n",
            "Epoch [9/10], Loss: 0.2385\n",
            "Epoch [10/10], Loss: 0.1939\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# 定义数据增强的转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load MNIST data from local CSV files\n",
        "train_data = pd.read_csv('./data/train.csv')\n",
        "test_data = pd.read_csv('./data/test.csv')\n",
        "\n",
        "# Convert to PyTorch tensors and apply transformations\n",
        "train_images = train_data.iloc[:, 1:].values.reshape(-1, 28, 28)\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_images = test_data.values.reshape(-1, 28, 28)\n",
        "\n",
        "# 将 NumPy 数组转换为 PIL 图像，然后应用数据增强\n",
        "train_images = [transform(Image.fromarray((image * 255).astype(np.uint8))) for image in train_images]\n",
        "test_images = [transform(Image.fromarray((image * 255).astype(np.uint8))) for image in test_images]\n",
        "\n",
        "train_images = torch.stack(train_images)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_images = torch.stack(test_images)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_images, torch.zeros(test_images.size(0), dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "model.eval()\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for data, _ in test_loader:\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predicted_labels.extend(predicted.numpy())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
