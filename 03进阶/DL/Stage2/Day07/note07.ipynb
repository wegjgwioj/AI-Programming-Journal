{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型部署：ONNX导出、Flask API部署、Docker打包\n",
    "如何将训练好的模型导出为ONNX格式，并使用Flask API进行部署，最后使用Docker打包，提供可访问的HTTP预测接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import onnx\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型导出为ONNX格式(开放式神经网络交换)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们有一个训练好的PyTorch模型\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 1)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "dummy_input = torch.randn(1, 10)\n",
    "torch.onnx.export(model, dummy_input, \"simple_model.onnx\")\n",
    "print(\"模型已导出为ONNX格式\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Flask API进行部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Flask应用\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 加载ONNX模型\n",
    "onnx_model = onnx.load(\"simple_model.onnx\")\n",
    "session = onnxruntime.InferenceSession(onnx_model.SerializeToString())\n",
    "\n",
    "# 定义预测接口\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    input_data = np.array(data['input']).astype(np.float32)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    result = session.run(None, {input_name: input_data})\n",
    "    return jsonify({'prediction': result[0].tolist()})\n",
    "\n",
    "# 运行Flask应用\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Docker打包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Dockerfile\n",
    "dockerfile_content = '''\n",
    "FROM python:3.8-slim\n",
    "WORKDIR /app\n",
    "COPY . /app\n",
    "RUN pip install flask onnx onnxruntime\n",
    "EXPOSE 5000\n",
    "CMD [\"python\", \"app.py\"]\n",
    "'''\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "print(\"Dockerfile已创建\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建和运行Docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Docker镜像\n",
    "!docker build -t simple_model_api .\n",
    "\n",
    "# 运行Docker容器\n",
    "!docker run -d -p 5000:5000 simple_model_api\n",
    "print(\"Docker容器已启动，API在http://localhost:5000/predict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myc1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
