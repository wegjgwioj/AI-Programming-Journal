{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElZQpz0jQfj9"
      },
      "source": [
        "# [卷积](https://www.bilibili.com/video/BV1Di4y1o7vX?spm_id_from=333.788.videopod.sections&vd_source=fcdea8640ba2eefed346095c371c5330)\n",
        "\n",
        "卷积核、池化、感受野、特征图\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCWMHskNQfkA"
      },
      "source": [
        "# CNN\n",
        "输入层-->卷积层-->池化层-->全连接层-->输出层\n",
        "[CS231n: CNN for Visual Recognition](https://cs231n.github.io/)（重点看Lecture 5, 7, 9）\n",
        "\n",
        "、ResNet（残差连接）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI_TlOEfQfkB"
      },
      "source": [
        "* LeNet\n",
        "[有关论文](./NIPS-1989-handwritten-digit-recognition-with-a-back-propagation-network-Paper.pdf)\n",
        "\n",
        "LeNet-5版本最为著名，也是LeNet系列中效果最佳的版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_67PNRppQfkB",
        "outputId": "fd735680-8eca-4b78-c6b6-4c065236c77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "# 导入pytorch库\n",
        "import torch\n",
        "# 导入torch.nn模块\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# 定义LeNet网络模型\n",
        "# MyLeNet5（子类）继承nn.Module（父类）\n",
        "class MyLeNet5(nn.Module):\n",
        "    # 子类继承中重新定义Module类的__init__()和forward()函数\n",
        "    # init()函数：进行初始化，申明模型中各层的定义\n",
        "    def __init__(self):\n",
        "        # super：引入父类的初始化方法给子类进行初始化\n",
        "        super(MyLeNet5, self).__init__()\n",
        "        # 卷积层，输入大小为28*28，输出大小为28*28，输入通道为1，输出为6，卷积核为5，扩充边缘为2\n",
        "        self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        # 使用sigmoid作为激活函数\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "        # AvgPool2d：二维平均池化操作\n",
        "        # 池化层，输入大小为28*28，输出大小为14*14，输入通道为6，输出为6，卷积核为2，步长为2\n",
        "        self.s2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        # 卷积层，输入大小为14*14，输出大小为10*10，输入通道为6，输出为16，卷积核为5\n",
        "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # 池化层，输入大小为10*10，输出大小为5*5，输入通道为16，输出为16，卷积核为2，步长为2\n",
        "        self.s4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        # 卷积层，输入大小为5*5，输出大小为1*1，输入通道为16，输出为120，卷积核为5\n",
        "        self.c5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "        # Flatten()：将张量（多维数组）平坦化处理，张量的第0维表示的是batch_size（数量），所以Flatten()默认从第二维开始平坦化\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 全连接层\n",
        "        # Linear（in_features，out_features）\n",
        "        # in_features指的是[batch_size, size]中的size,即样本的大小\n",
        "        # out_features指的是[batch_size，output_size]中的output_size，样本输出的维度大小，也代表了该全连接层的神经元个数\n",
        "        self.f6 = nn.Linear(120, 84)\n",
        "        # 全连接层&输出层\n",
        "        self.output = nn.Linear(84, 10)\n",
        "\n",
        "    # forward()：定义前向传播过程,描述了各层之间的连接关系\n",
        "    def forward(self, x):\n",
        "        # x输入为28*28*1， 输出为28*28*6\n",
        "        x = self.Sigmoid(self.c1(x))\n",
        "        # x输入为28*28*6，输出为14*14*6\n",
        "        x = self.s2(x)\n",
        "        # x输入为14*14*6，输出为10*10*16\n",
        "        x = self.Sigmoid(self.c3(x))\n",
        "        # x输入为10*10*16，输出为5*5*16\n",
        "        x = self.s4(x)\n",
        "        # x输入为5*5*16，输出为1*1*120\n",
        "        x = self.c5(x)\n",
        "        x = self.flatten(x)\n",
        "        # x输入为120，输出为84\n",
        "        x = self.f6(x)\n",
        "        # x输入为84，输出为10\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# 测试代码\n",
        "# 每个python模块（python文件）都包含内置的变量 __name__，当该模块被直接执行的时候，__name__ 等于文件名（包含后缀 .py ）\n",
        "# 如果该模块 import 到其他模块中，则该模块的 __name__ 等于模块名称（不包含后缀.py）\n",
        "# “__main__” 始终指当前执行模块的名称（包含后缀.py）\n",
        "# if确保只有单独运行该模块时，此表达式才成立，才可以进入此判断语法，执行其中的测试代码，反之不行\n",
        "if __name__ == \"__main__\":\n",
        "    # rand:返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数，此处为四维张量\n",
        "    x = torch.rand([1, 1, 28, 28])\n",
        "    # 模型实例化\n",
        "    model = MyLeNet5()\n",
        "    y = model(x)\n",
        "    print(y.shape)\n",
        "    # torch.Size([1, 10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USgosOqEVeQR",
        "outputId": "a077773f-da28-4f10-b2a2-1dd3ad008e0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39.0%"
          ]
        }
      ],
      "source": [
        "#train\n",
        "# lr_scheduler：提供一些根据epoch训练次数来调整学习率的方法\n",
        "from torch.optim import lr_scheduler\n",
        "# torchvision：PyTorch的一个图形库，服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型\n",
        "# transforms：主要是用于常见的一些图形变换\n",
        "# datasets：包含加载数据的函数及常用的数据集接口\n",
        "from torchvision import datasets, transforms\n",
        "# os：operating system（操作系统），os模块封装了常见的文件和目录操作\n",
        "import os\n",
        "\n",
        "# 数据转化为Tensor格式\n",
        "# Compose()：将多个transforms的操作整合在一起\n",
        "# ToTensor(): 将numpy的ndarray或PIL.Image读的图片转换成形状为(C,H, W)的Tensor格式，且归一化到[0,1.0]之间\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 加载训练数据集\n",
        "# MNIST数据集来自美国国家标准与技术研究所, 训练集 (training set)、测试集(test set)由分别由来自250个不同人手写的数字构成\n",
        "# MNIST数据集包含：Training set images、Training set images、Test set images、Test set labels\n",
        "# train = true是训练集，false为测试集\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_transform, download=True)\n",
        "# DataLoader：将读取的数据按照batch size大小封装并行训练\n",
        "# dataset (Dataset)：加载的数据集\n",
        "# batch_size (int, optional)：每个batch加载多少个样本(默认: 1)\n",
        "# shuffle (bool, optional)：设置为True时会在每个epoch重新打乱数据(默认: False)\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "# 加载测试数据集\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_transform, download=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 如果有NVIDA显卡，转到GPU训练，否则用CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 模型实例化，将模型转到device\n",
        "model = MyLeNet5().to(device)\n",
        "\n",
        "# 定义损失函数（交叉熵损失）\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 定义优化器(随机梯度下降法)\n",
        "# params(iterable)：要训练的参数，一般传入的是model.parameters()\n",
        "# lr(float)：learning_rate学习率，也就是步长\n",
        "# momentum(float, 可选)：动量因子（默认：0），矫正优化率\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "# 学习率，每隔10轮变为原来的0.1\n",
        "# StepLR：用于调整学习率，一般情况下会设置随着epoch的增大而逐渐减小学习率从而达到更好的训练效果\n",
        "# optimizer （Optimizer）：需要更改学习率的优化器\n",
        "# step_size（int）：每训练step_size个epoch，更新一次参数\n",
        "# gamma（float）：更新lr的乘法因子\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "\n",
        "# 定义训练函数\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    loss, current, n = 0.0, 0.0, 0\n",
        "    # dataloader: 传入数据（数据包括：训练数据和标签）\n",
        "    # enumerate()：用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，一般用在for循环当中\n",
        "    # enumerate返回值有两个：一个是序号，一个是数据（包含训练数据和标签）\n",
        "    # x：训练数据（inputs）(tensor类型的），y：标签（labels）(tensor类型的）\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        # 前向传播\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        # 计算训练值\n",
        "        output = model(x)\n",
        "        # 计算观测值（label）与训练值的损失函数\n",
        "        cur_loss = loss_fn(output, y)\n",
        "        # torch.max(input, dim)函数\n",
        "        # input是具体的tensor，dim是max函数索引的维度，0是每列的最大值，1是每行的最大值输出\n",
        "        # 函数会返回两个tensor，第一个tensor是每行的最大值；第二个tensor是每行最大值的索引\n",
        "        _, pred = torch.max(output, axis=1)\n",
        "        # 计算每批次的准确率\n",
        "        # output.shape[0]一维长度为该批次的数量\n",
        "        # torch.sum()对输入的tensor数据的某一维度求和\n",
        "        cur_acc = torch.sum(y == pred) / output.shape[0]\n",
        "\n",
        "        # 反向传播\n",
        "        # 清空过往梯度\n",
        "        optimizer.zero_grad()\n",
        "        # 反向传播，计算当前梯度\n",
        "        cur_loss.backward()\n",
        "        # 根据梯度更新网络参数\n",
        "        optimizer.step()\n",
        "        # .item()：得到元素张量的元素值\n",
        "        loss += cur_loss.item()\n",
        "        current += cur_acc.item()\n",
        "        n = n + 1\n",
        "\n",
        "    train_loss = loss / n\n",
        "    train_acc = current / n\n",
        "    # 计算训练的错误率\n",
        "    print('train_loss' + str(train_loss))\n",
        "    # 计算训练的准确率\n",
        "    print('train_acc' + str(train_acc))\n",
        "\n",
        "\n",
        "# 定义验证函数\n",
        "def val(dataloader, model, loss_fn):\n",
        "    # model.eval()：设置为验证模式，如果模型中有Batch Normalization或Dropout，则不启用，以防改变权值\n",
        "    model.eval()\n",
        "    loss, current, n = 0.0, 0.0, 0\n",
        "    # with torch.no_grad()：将with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为\n",
        "    with torch.no_grad():\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            # 前向传播\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x)\n",
        "            cur_loss = loss_fn(output, y)\n",
        "            _, pred = torch.max(output, axis=1)\n",
        "            cur_acc = torch.sum(y == pred) / output.shape[0]\n",
        "            loss += cur_loss.item()\n",
        "            current += cur_acc.item()\n",
        "            n = n + 1\n",
        "        # 计算验证的错误率\n",
        "        print(\"val_loss：\" + str(loss / n))\n",
        "        # 计算验证的准确率\n",
        "        print(\"val_acc：\" + str(current / n))\n",
        "        # 返回模型准确率\n",
        "        return current / n\n",
        "\n",
        "\n",
        "# 开始训练\n",
        "# 训练次数\n",
        "epoch = 10\n",
        "# 用于判断最佳模型\n",
        "min_acc = 0\n",
        "for t in range(epoch):\n",
        "    print(f'epoch {t + 1}\\n---------------')\n",
        "    # 训练模型\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    # 验证模型\n",
        "    a = val(test_dataloader, model, loss_fn)\n",
        "    # 保存最好的模型权重\n",
        "    if a > min_acc:\n",
        "        folder = 'save_model'\n",
        "        # path.exists：判断括号里的文件是否存在，存在为True，括号内可以是文件路径\n",
        "        if not os.path.exists(folder):\n",
        "            # os.mkdir() ：用于以数字权限模式创建目录\n",
        "            os.mkdir('save_model')\n",
        "        min_acc = a\n",
        "        print('save best model')\n",
        "        # torch.save(state, dir)保存模型等相关参数，dir表示保存文件的路径+保存文件名\n",
        "        # model.state_dict()：返回的是一个OrderedDict，存储了网络结构的名字和对应的参数\n",
        "        torch.save(model.state_dict(), 'save_model/best_model.pth')\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3OStBtsalBq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g91QSFv2VfWN",
        "outputId": "348e8ee9-30c1-4307-c051-6c27b2be1a57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-83ab7eb6674a>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"./save_model/best_model.pth\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted: \"7\", actual:\"7\"\n",
            "predicted: \"2\", actual:\"2\"\n",
            "predicted: \"1\", actual:\"1\"\n",
            "predicted: \"0\", actual:\"0\"\n",
            "predicted: \"4\", actual:\"4\"\n",
            "predicted: \"1\", actual:\"1\"\n",
            "predicted: \"4\", actual:\"4\"\n",
            "predicted: \"9\", actual:\"9\"\n",
            "predicted: \"6\", actual:\"5\"\n",
            "predicted: \"9\", actual:\"9\"\n"
          ]
        }
      ],
      "source": [
        "#predict\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "# Compose()：将多个transforms的操作整合在一起\n",
        "data_transform = transforms.Compose([\n",
        "    # ToTensor()：数据转化为Tensor格式\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 加载训练数据集\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_transform, download=True)\n",
        "# 给训练集创建一个数据加载器, shuffle=True用于打乱数据集，每次都会以不同的顺序返回\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 加载测试数据集\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_transform, download=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# 如果有NVIDA显卡，转到GPU训练，否则用CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 模型实例化，将模型转到device\n",
        "model = MyLeNet5().to(device)\n",
        "\n",
        "# 加载train.py里训练好的模型\n",
        "model.load_state_dict(torch.load(\"./save_model/best_model.pth\"))\n",
        "\n",
        "# 结果类型\n",
        "classes = [\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\",\n",
        "]\n",
        "\n",
        "# 把Tensor转化为图片，方便可视化\n",
        "show = ToPILImage()\n",
        "\n",
        "# 进入验证阶段\n",
        "for i in range(10):\n",
        "    x, y = test_dataset[i][0], test_dataset[i][1]\n",
        "    # show()：显示图片\n",
        "    show(x).show()\n",
        "    # unsqueeze(input, dim)，input(Tensor)：输入张量，dim (int)：插入维度的索引，最终将张量维度扩展为4维\n",
        "    x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
        "    with torch.no_grad():\n",
        "        pred = model(x)\n",
        "        # argmax(input)：返回指定维度最大值的序号\n",
        "        # 得到验证类别中数值最高的那一类，再对应classes中的那一类\n",
        "        predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
        "        # 输出预测值与真实值\n",
        "        print(f'predicted: \"{predicted}\", actual:\"{actual}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnOaAMYiallC"
      },
      "source": [
        "# ResNet（残差连接）\n",
        "* 来历 ：\n",
        "残差神经网络(ResNet)是由微软研究院的何恺明等人提出的， 斩获2015年ImageNet竞赛中分类任务第一名， 目标检测第一名。 残差神经网络的主要贡献是发现了“退化现象（Degradation）”，并针对退化现象发明了 “直连边/短连接（Shortcut connection）”，极大的消除了深度过大的神经网络训练困难问题。神经网络的“深度”首次突破了100层、最大的神经网络甚至超过了1000层。\n",
        "\n",
        "* 不同于GoogLeNet，ResNet在每个卷积层后增加了批量规一化层。\n",
        "---\n",
        "\n",
        "\n",
        "1.超深的网络结构(突破1000层)\n",
        "\n",
        "网络深度为什么重要？因为CNN能够提取low/mid/high-level的特征，网络的层数越多，意味着能够提取到不同level的特征越丰富。并且，越深的网络提取的特征越抽象，越具有语义信息。\n",
        "\n",
        "2.使用Batch Normalization\n",
        "\n",
        "为什么不能简单地增加网络层数？对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸。Batch Normalization可以解决该问题的，因此可以训练到几十层的网络。\n",
        "\n",
        "3.残差块\n",
        "\n",
        "随着网络层数增加，出现了新的问题：退化问题，在训练集上准确率饱和甚至下降了。这个不能解释为过拟合，因为过拟合表现为在训练集上表现更好才对。退化问题说明了深度网络不能很简单地被很好地优化。作者通过实验说明：通过浅层网络y=x 等同映射构造深层模型，结果深层模型并没有比浅层网络有更低甚至等同的错误率，推断退化问题可能是因为深层的网络很那难通过训练利用多层网络拟合同等函数。\n",
        "\n",
        "\n",
        "*  怎么解决退化问题？\n",
        "\n",
        "深度残差网络。如果深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。所以要解决的就是学习恒等映射函数。但是直接让一些层去拟合一个潜在的恒等映射函数H(x) = x，比较困难，这可能就是深层网络难以训练的原因。但是，如果把网络设计为H(x) = F(x) + x。我们可以转换为学习一个残差函数F(x) = H(x) - x. 只要F(x)=0，就构成了一个恒等映射H(x) = x. 此外，拟合残差会更加容易。\n",
        "\n",
        "总的来说，一是其导数总比原导数加1，这样即使原导数很小时，也能传递下去，能解决梯度消失的问题； 二是y=f(x)+x式子中引入了恒等映射（当f(x)=0时，y=2），解决了深度增加时神经网络的退化问题。\n",
        "\n",
        "4.结构简单\n",
        "\n",
        "虽然ResNet的主体结构跟GoogLeNet类似，但ResNet结构更简单，修改也更方便，因此ResNet迅速被广泛使用。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jyl5y3vpcXLO"
      },
      "outputs": [],
      "source": [
        " # 定义ResNet18/34的残差结构，为2个3x3的卷积\n",
        "class BasicBlock(nn.Module):\n",
        "    # 判断残差结构中，主分支的卷积核个数是否发生变化，不变则为1\n",
        "    expansion = 1\n",
        "\n",
        "    # init()：进行初始化，申明模型中各层的定义\n",
        "    # downsample=None对应实线残差结构，否则为虚线残差结构\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
        "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # 使用批量归一化\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        # 使用ReLU作为激活函数\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
        "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    # forward()：定义前向传播过程,描述了各层之间的连接关系\n",
        "    def forward(self, x):\n",
        "        # 残差块保留原始输入\n",
        "        identity = x\n",
        "        # 如果是虚线残差结构，则进行下采样\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        # -----------------------------------------\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # 主分支与shortcut分支数据相加\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# 定义ResNet50/101/152的残差结构，为1x1+3x3+1x1的卷积\n",
        "class Bottleneck(nn.Module):\n",
        "    # expansion是指在每个小残差块内，减小尺度增加维度的倍数，如64*4=256\n",
        "    # Bottleneck层输出通道是输入的4倍\n",
        "    expansion = 4\n",
        "\n",
        "    # init()：进行初始化，申明模型中各层的定义\n",
        "    # downsample=None对应实线残差结构，否则为虚线残差结构，专门用来改变x的通道数\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n",
        "                 groups=1, width_per_group=64):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        width = int(out_channel * (width_per_group / 64.)) * groups\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "        # 使用批量归一化\n",
        "        self.bn1 = nn.BatchNorm2d(width)\n",
        "        # -----------------------------------------\n",
        "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,\n",
        "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(width)\n",
        "        # -----------------------------------------\n",
        "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel * self.expansion,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "        # 使用ReLU作为激活函数\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    # forward()：定义前向传播过程,描述了各层之间的连接关系\n",
        "    def forward(self, x):\n",
        "        # 残差块保留原始输入\n",
        "        identity = x\n",
        "        # 如果是虚线残差结构，则进行下采样\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        # 主分支与shortcut分支数据相加\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# 定义ResNet类\n",
        "class ResNet(nn.Module):\n",
        "    # 初始化函数\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 blocks_num,\n",
        "                 num_classes=1000,\n",
        "                 include_top=True,\n",
        "                 groups=1,\n",
        "                 width_per_group=64):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.include_top = include_top\n",
        "        # maxpool的输出通道数为64，残差结构输入通道数为64\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.groups = groups\n",
        "        self.width_per_group = width_per_group\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
        "                               padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # 浅层的stride=1，深层的stride=2\n",
        "        # block：定义的两种残差模块\n",
        "        # block_num：模块中残差块的个数\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        if self.include_top:\n",
        "            # 自适应平均池化，指定输出（H，W），通道数不变\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "            # 全连接层\n",
        "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "        # 遍历网络中的每一层\n",
        "        # 继承nn.Module类中的一个方法:self.modules(), 他会返回该网络中的所有modules\n",
        "        for m in self.modules():\n",
        "            # isinstance(object, type)：如果指定对象是指定类型，则isinstance()函数返回True\n",
        "            # 如果是卷积层\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # kaiming正态分布初始化，使得Conv2d卷积层反向传播的输出的方差都为1\n",
        "                # fan_in：权重是通过线性层（卷积或全连接）隐性确定\n",
        "                # fan_out：通过创建随机矩阵显式创建权重\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    # 定义残差模块，由若干个残差块组成\n",
        "    # block：定义的两种残差模块，channel：该模块中所有卷积层的基准通道数。block_num：模块中残差块的个数\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        # 如果满足条件，则是虚线残差结构\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel,\n",
        "                            channel,\n",
        "                            downsample=downsample,\n",
        "                            stride=stride,\n",
        "                            groups=self.groups,\n",
        "                            width_per_group=self.width_per_group))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel,\n",
        "                                channel,\n",
        "                                groups=self.groups,\n",
        "                                width_per_group=self.width_per_group))\n",
        "        # Sequential：自定义顺序连接成模型，生成网络结构\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    # forward()：定义前向传播过程,描述了各层之间的连接关系\n",
        "    def forward(self, x):\n",
        "        # 无论哪种ResNet，都需要的静态层\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        # 动态层\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.include_top:\n",
        "            x = self.avgpool(x)\n",
        "            x = torch.flatten(x, 1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ResNet()中block参数对应的位置是BasicBlock或Bottleneck\n",
        "# ResNet()中blocks_num[0-3]对应[3, 4, 6, 3]，表示残差模块中的残差数\n",
        "# 34层的resnet\n",
        "def resnet34(num_classes=1000, include_top=True):\n",
        "    # https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
        "\n",
        "\n",
        "# 50层的resnet\n",
        "def resnet50(num_classes=1000, include_top=True):\n",
        "    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
        "\n",
        "\n",
        "# 101层的resnet\n",
        "def resnet101(num_classes=1000, include_top=True):\n",
        "    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGIBEex7dQRr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "# 训练resnet34\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 如果有NVIDA显卡，转到GPU训练，否则用CPU\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    data_transform = {\n",
        "        # 训练\n",
        "        # Compose()：将多个transforms的操作整合在一起\n",
        "        \"train\": transforms.Compose([\n",
        "            # RandomResizedCrop(224)：将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为给定大小\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            # RandomVerticalFlip()：以0.5的概率竖直翻转给定的PIL图像\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            # ToTensor()：数据转化为Tensor格式\n",
        "            transforms.ToTensor(),\n",
        "            # Normalize()：将图像的像素值归一化到[-1,1]之间，使模型更容易收敛\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "        # 验证\n",
        "        \"val\": transforms.Compose([transforms.Resize(256),\n",
        "                                   transforms.CenterCrop(224),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "    # abspath()：获取文件当前目录的绝对路径\n",
        "    # join()：用于拼接文件路径，可以传入多个路径\n",
        "    # getcwd()：该函数不需要传递参数，获得当前所运行脚本的路径\n",
        "    data_root = os.path.abspath(os.getcwd())\n",
        "    # 得到数据集的路径\n",
        "    image_path = os.path.join(data_root, \"flower_data\")\n",
        "    # exists()：判断括号里的文件是否存在，可以是文件路径\n",
        "    # 如果image_path不存在，序会抛出AssertionError错误，报错为参数内容“ ”\n",
        "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
        "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
        "                                         transform=data_transform[\"train\"])\n",
        "    # 训练集长度\n",
        "    train_num = len(train_dataset)\n",
        "\n",
        "    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
        "    # class_to_idx：获取分类名称对应索引\n",
        "    flower_list = train_dataset.class_to_idx\n",
        "    # dict()：创建一个新的字典\n",
        "    # 循环遍历数组索引并交换val和key的值重新赋值给数组，这样模型预测的直接就是value类别值\n",
        "    cla_dict = dict((val, key) for key, val in flower_list.items())\n",
        "    # 把字典编码成json格式\n",
        "    json_str = json.dumps(cla_dict, indent=4)\n",
        "    # 把字典类别索引写入json文件\n",
        "    with open('class_indices.json', 'w') as json_file:\n",
        "        json_file.write(json_str)\n",
        "\n",
        "    # 一次训练载入16张图像\n",
        "    batch_size = 16\n",
        "    # 确定进程数\n",
        "    # min()：返回给定参数的最小值，参数可以为序列\n",
        "    # cpu_count()：返回一个整数值，表示系统中的CPU数量，如果不确定CPU的数量，则不返回任何内容\n",
        "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "    # DataLoader：将读取的数据按照batch size大小封装给训练集\n",
        "    # dataset (Dataset)：输入的数据集\n",
        "    # batch_size (int, optional)：每个batch加载多少个样本，默认: 1\n",
        "    # shuffle (bool, optional)：设置为True时会在每个epoch重新打乱数据，默认: False\n",
        "    # num_workers(int, optional): 决定了有几个进程来处理，默认为0意味着所有的数据都会被load进主进程\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=nw)\n",
        "    # 加载测试数据集\n",
        "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
        "                                            transform=data_transform[\"val\"])\n",
        "    # 测试集长度\n",
        "    val_num = len(validate_dataset)\n",
        "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
        "                                                  batch_size=batch_size, shuffle=False,\n",
        "                                                  num_workers=nw)\n",
        "\n",
        "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
        "                                                                           val_num))\n",
        "\n",
        "    # 模型实例化\n",
        "    net = resnet34()\n",
        "    net.to(device)\n",
        "    # 加载预训练模型权重\n",
        "    # model_weight_path = \"./resnet34-pre.pth\"\n",
        "    # exists()：判断括号里的文件是否存在，可以是文件路径\n",
        "    # assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
        "    # net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
        "    # 输入通道数\n",
        "    # in_channel = net.fc.in_features\n",
        "    # 全连接层\n",
        "    # net.fc = nn.Linear(in_channel, 5)\n",
        "\n",
        "    # 定义损失函数（交叉熵损失）\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 抽取模型参数\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    # 定义adam优化器\n",
        "    # params(iterable)：要训练的参数，一般传入的是model.parameters()\n",
        "    # lr(float)：learning_rate学习率，也就是步长，默认：1e-3\n",
        "    optimizer = optim.Adam(params, lr=0.0001)\n",
        "\n",
        "    # 迭代次数（训练次数）\n",
        "    epochs = 3\n",
        "    # 用于判断最佳模型\n",
        "    best_acc = 0.0\n",
        "    # 最佳模型保存地址\n",
        "    save_path = './resNet34.pth'\n",
        "    train_steps = len(train_loader)\n",
        "    for epoch in range(epochs):\n",
        "        # 训练\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        # tqdm：进度条显示\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        # train_bar: 传入数据（数据包括：训练数据和标签）\n",
        "        # enumerate()：将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在for循环当中\n",
        "        # enumerate返回值有两个：一个是序号，一个是数据（包含训练数据和标签）\n",
        "        # x：训练数据（inputs）(tensor类型的），y：标签（labels）(tensor类型）\n",
        "        for step, data in enumerate(train_bar):\n",
        "            # 前向传播\n",
        "            images, labels = data\n",
        "            # 计算训练值\n",
        "            logits = net(images.to(device))\n",
        "            # 计算损失\n",
        "            loss = loss_function(logits, labels.to(device))\n",
        "            # 反向传播\n",
        "            # 清空过往梯度\n",
        "            optimizer.zero_grad()\n",
        "            # 反向传播，计算当前梯度\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # item()：得到元素张量的元素值\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # 进度条的前缀\n",
        "            # .3f：表示浮点数的精度为3（小数位保留3位）\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
        "                                                                     epochs,\n",
        "                                                                     loss)\n",
        "\n",
        "        # 测试\n",
        "        # eval()：如果模型中有Batch Normalization和Dropout，则不启用，以防改变权值\n",
        "        net.eval()\n",
        "        acc = 0.0\n",
        "        # 清空历史梯度，与训练最大的区别是测试过程中取消了反向传播\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                outputs = net(val_images.to(device))\n",
        "                # torch.max(input, dim)函数\n",
        "                # input是具体的tensor，dim是max函数索引的维度，0是每列的最大值，1是每行的最大值输出\n",
        "                # 函数会返回两个tensor，第一个tensor是每行的最大值；第二个tensor是每行最大值的索引\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                # 对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回True；若不同，返回False\n",
        "                # .sum()对输入的tensor数据的某一维度求和\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
        "                                                           epochs)\n",
        "\n",
        "        val_accurate = acc / val_num\n",
        "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
        "\n",
        "        # 保存最好的模型权重\n",
        "        if val_accurate > best_acc:\n",
        "            best_acc = val_accurate\n",
        "            # torch.save(state, dir)保存模型等相关参数，dir表示保存文件的路径+保存文件名\n",
        "            # model.state_dict()：返回的是一个OrderedDict，存储了网络结构的名字和对应的参数\n",
        "            torch.save(net.state_dict(), save_path)\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_ZnUx_LdrWh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 如果有NVIDA显卡,转到GPU训练，否则用CPU\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 将多个transforms的操作整合在一起\n",
        "    data_transform = transforms.Compose(\n",
        "        [transforms.Resize(256),\n",
        "         transforms.CenterCrop(224),\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    # 加载图片\n",
        "    img_path = \"../tulip.jpg\"\n",
        "    # 确定图片存在，否则反馈错误\n",
        "    assert os.path.exists(img_path), \"file: '{}' dose not exist.\".format(img_path)\n",
        "    img = Image.open(img_path)\n",
        "    # imshow()：对图像进行处理并显示其格式，show()则是将imshow()处理后的函数显示出来\n",
        "    plt.imshow(img)\n",
        "    # [C, H, W]，转换图像格式\n",
        "    img = data_transform(img)\n",
        "    # [N, C, H, W]，增加一个维度N\n",
        "    img = torch.unsqueeze(img, dim=0)\n",
        "\n",
        "    # 获取结果类型\n",
        "    json_path = './class_indices.json'\n",
        "    # 确定路径存在，否则反馈错误\n",
        "    assert os.path.exists(json_path), \"file: '{}' dose not exist.\".format(json_path)\n",
        "    # 读取内容\n",
        "    with open(json_path, \"r\") as f:\n",
        "        class_indict = json.load(f)\n",
        "\n",
        "    # 模型实例化，将模型转到device，结果类型有5种\n",
        "    model = resnet34(num_classes=5).to(device)\n",
        "\n",
        "    # 载入模型权重\n",
        "    weights_path = \"./resNet34.pth\"\n",
        "    # 确定模型存在，否则反馈错误\n",
        "    assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
        "    # 加载训练好的模型参数\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "\n",
        "    # 进入验证阶段\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 预测类别\n",
        "        # squeeze()：维度压缩，返回一个tensor（张量），其中input中大小为1的所有维都已删除\n",
        "        output = torch.squeeze(model(img.to(device))).cpu()\n",
        "        # softmax：归一化指数函数，将预测结果输入进行非负性和归一化处理，最后将某一维度值处理为0-1之内的分类概率\n",
        "        predict = torch.softmax(output, dim=0)\n",
        "        # argmax(input)：返回指定维度最大值的序号\n",
        "        # .numpy()：把tensor转换成numpy的格式\n",
        "        predict_cla = torch.argmax(predict).numpy()\n",
        "\n",
        "    # 输出的预测值与真实值\n",
        "    print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_cla)],\n",
        "                                                 predict[predict_cla].numpy())\n",
        "\n",
        "    # 图片标题\n",
        "    plt.title(print_res)\n",
        "    for i in range(len(predict)):\n",
        "        print(\"class: {:10}   prob: {:.3}\".format(class_indict[str(i)],\n",
        "                                                  predict[i].numpy()))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYwP3-zvd4eR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from shutil import copy, rmtree\n",
        "import random\n",
        "\n",
        "\n",
        "def mk_file(file_path: str):\n",
        "    if os.path.exists(file_path):\n",
        "        # 如果文件夹存在，则先删除原文件夹再重新创建\n",
        "        rmtree(file_path)\n",
        "    os.makedirs(file_path)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 保证随机可复现\n",
        "    random.seed(0)\n",
        "\n",
        "    # 将数据集中10%的数据划分到验证集中\n",
        "    split_rate = 0.1\n",
        "\n",
        "    # 指向解压后的flower_photos文件夹\n",
        "    # getcwd()：该函数不需要传递参数，获得当前所运行脚本的路径\n",
        "    cwd = os.getcwd()\n",
        "    # join()：用于拼接文件路径，可以传入多个路径\n",
        "    data_root = os.path.join(cwd, \"flower_data\")\n",
        "    origin_flower_path = os.path.join(data_root, \"flower_photos\")\n",
        "    # 确定路径存在，否则反馈错误\n",
        "    assert os.path.exists(origin_flower_path), \"path '{}' does not exist.\".format(origin_flower_path)\n",
        "    # isdir()：判断某一路径是否为目录\n",
        "    # listdir()：返回指定的文件夹包含的文件或文件夹的名字的列表\n",
        "    flower_class = [cla for cla in os.listdir(origin_flower_path)\n",
        "                    if os.path.isdir(os.path.join(origin_flower_path, cla))]\n",
        "\n",
        "    # 创建训练集train文件夹，并由类名在其目录下创建子目录\n",
        "    train_root = os.path.join(data_root, \"train\")\n",
        "    mk_file(train_root)\n",
        "    for cla in flower_class:\n",
        "        # 建立每个类别对应的文件夹\n",
        "        mk_file(os.path.join(train_root, cla))\n",
        "\n",
        "    # 创建验证集val文件夹，并由类名在其目录下创建子目录\n",
        "    val_root = os.path.join(data_root, \"val\")\n",
        "    mk_file(val_root)\n",
        "    for cla in flower_class:\n",
        "        # 建立每个类别对应的文件夹\n",
        "        mk_file(os.path.join(val_root, cla))\n",
        "\n",
        "    # 遍历所有类别的图像并按比例分成训练集和验证集\n",
        "    for cla in flower_class:\n",
        "        cla_path = os.path.join(origin_flower_path, cla)\n",
        "        # iamges列表存储了该目录下所有图像的名称\n",
        "        images = os.listdir(cla_path)\n",
        "        num = len(images)\n",
        "        # 随机采样验证集的索引\n",
        "        # 从images列表中随机抽取k个图像名称\n",
        "        # random.sample：用于截取列表的指定长度的随机数，返回列表\n",
        "        # eval_index保存验证集val的图像名称\n",
        "        eval_index = random.sample(images, k=int(num*split_rate))\n",
        "        for index, image in enumerate(images):\n",
        "            if image in eval_index:\n",
        "                # 将分配至验证集中的文件复制到相应目录\n",
        "                image_path = os.path.join(cla_path, image)\n",
        "                new_path = os.path.join(val_root, cla)\n",
        "                copy(image_path, new_path)\n",
        "            else:\n",
        "                # 将分配至训练集中的文件复制到相应目录\n",
        "                image_path = os.path.join(cla_path, image)\n",
        "                new_path = os.path.join(train_root, cla)\n",
        "                copy(image_path, new_path)\n",
        "                # '\\r'回车，回到当前行的行首，而不会换到下一行，如果接着输出，本行以前的内容会被逐一覆盖\n",
        "                # end=\"\"：将print自带的换行用end中指定的str代替\n",
        "            print(\"\\r[{}] processing [{}/{}]\".format(cla, index+1, num), end=\"\")\n",
        "        print()\n",
        "\n",
        "    print(\"processing done!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
