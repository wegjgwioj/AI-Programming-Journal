# 分布式训练多GPU训练（DDP/Horovod）、TPU使用 PyTorch Lightning/TF Strategy

## 分布式训练

分布式训练是指在多个计算节点上并行训练模型，以加速训练过程和处理大规模数据集。

### 多GPU训练

多GPU训练是分布式训练的一种形式，通过在多个GPU上并行训练模型来提高训练速度和效率。常见的多GPU训练框架包括 DDP 和 Horovod。

#### DDP (Distributed Data Parallel)

DDP 是 PyTorch 提供的分布式数据并行训练框架，通过在多个GPU上并行训练模型来加速训练过程。

#### Horovod

Horovod 是一个开源的分布式深度学习训练框架，支持多种深度学习框架（如 TensorFlow、Keras 和 PyTorch），通过简化分布式训练代码来提高训练效率。

## TPU 使用

TPU（Tensor Processing Unit）是 Google 专门为加速机器学习工作负载而设计的硬件加速器。TPU 可以显著提高模型训练和推理的速度。

### PyTorch Lightning

PyTorch Lightning 是一个轻量级的 PyTorch 封装库，简化了分布式训练和 TPU 使用的代码。通过 PyTorch Lightning，用户可以轻松地在 TPU 上训练模型。

### TF Strategy

TF Strategy 是 TensorFlow 提供的分布式训练策略，通过简化分布式训练代码来提高训练效率。TF Strategy 支持多种硬件加速器，包括 GPU 和 TPU。
