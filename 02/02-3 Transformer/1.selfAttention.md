# Q/K/V

Q/K/V矩阵是Transformers Block MHA的重要组成部分，当一个文本Token过来的时候，文本Token的Normalization矩阵会分别和Q、K、V的权重矩阵进行矩阵乘法操作，得到三个不同的矩阵，以进入后面的计算过程。


## **Query (Q)：**

 **角色** ：Query向量代表当前正在处理的token或位置，它表示模型需要“查询”的信息。

 **作用** ：在自注意力机制中，Query用于与所有的Key进行比较，以确定每个Key与当前token的相关性。这个比较的结果决定了Value的加权和，从而生成当前token的输出。

 **变化性** ：在自回归推理过程中，每个新生成的token都会有一个新的Query向量，它只依赖于当前token的信息。

## **Key (K)：**

**角色**：Key矩阵是输入序列的“可查询表示”，用于被 Query 匹配。

**作用：**

* 与 Query 共同计算注意力权重，决定关注哪些位置；
* 通过多头机制学习多样化的关系模式；
* 为 Value 矩阵提供加权聚合的依据。

**稳定性** ：在自回归推理中，对于已经生成的token，其Key向量在后续的推理过程中会被重复使用，因为它们代表的是已经确定的token信息。

## **Value (V)：**

 **角色** ：Value向量包含序列中每个token的实际内容或特征，它对生成当前token的输出有贡献。

 **作用** ：Value向量根据与Query的相似度得分（由Key确定）被加权求和，生成当前token的输出。

 **稳定性** ：与Key类似，对于已经生成的token，其Value向量在后续的推理过程中也会被重复使用。


# 数学推导：Q/K/V矩阵计算 → 注意力权重 → 上下文向量

以下是一个基于三阶张量（包含批量维度）的简化Self-Attention数学推导示例，假设输入序列为 **2个样本(**$batch_{size}=2）$，每个样本包含 **3个位置**($seq_{len}=3$)，每个位置的向量维度为 **4($d_{model}=4$)**，并设定Key的维度为 **2**（$d_k$=2）。

---

### **1. 输入定义**

假设输入张量 $ X \in \mathbb{R}^{2 \times 3 \times 4} $ 为：

```python
X = [
    # 样本1（3个位置，每个位置4维）
    [[1, 2, 3, 4],
     [5, 6, 7, 8],
     [9, 10, 11, 12]],
  
    # 样本2
    [[0, 1, 0, 1],
     [2, 3, 2, 3],
     [4, 5, 4, 5]]
]
```

---

### **2. 投影矩阵定义**

设定可学习的权重矩阵：

- $ W^Q, W^K \in \mathbb{R}^{4 \times 2} $
- $ W^V \in \mathbb{R}^{4 \times 2} $

为简化计算，手动指定它们的值为：

```python
WQ = [[1, 0],
      [0, 1],
      [1, 0],
      [0, 1]]

WK = [[0, 1],
      [1, 0],
      [0, 1],
      [1, 0]]

WV = [[1, 1],
      [0, 0],
      [1, 1],
      [0, 0]]
```

---

### **3. 计算Q, K, V**

通过矩阵乘法将输入投影到低维空间：

#### **样本1的Q计算**：

$$
Q_1 = \begin{bmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & 10 & 11 & 12
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\
0 & 1 \\
1 & 0 \\
0 & 1
\end{bmatrix}
= \begin{bmatrix}
1*1 + 2*0 + 3*1 + 4*0 & 1*0 + 2*1 + 3*0 + 4*1 \\
5*1 + 6*0 + 7*1 + 8*0 & 5*0 + 6*1 + 7*0 + 8*1 \\
9*1 + 10*0 + 11*1 + 12*0 & 9*0 + 10*1 + 11*0 + 12*1
\end{bmatrix}
= \begin{bmatrix}
4 & 6 \\
12 & 14 \\
20 & 22
\end{bmatrix}
$$

同理计算其他样本的 \( Q, K, V \)，最终得到：

- $ Q \in \mathbb{R}^{2 \times 3 \times 2} $
- $K \in \mathbb{R}^{2 \times 3 \times 2} $
- $V \in \mathbb{R}^{2 \times 3 \times 2} $

---

### **4. 注意力分数**

对每个样本，计算 $ QK^T $ 并缩放：

#### **样本1的注意力分数**：

$$
Q_1 K_1^T = \begin{bmatrix}
4 & 6 \\
12 & 14 \\
20 & 22
\end{bmatrix}
\begin{bmatrix}
4 & 12 & 20 \\
6 & 14 & 22
\end{bmatrix}
= \begin{bmatrix}
4*4 + 6*6 & 4*12 + 6*14 & 4*20 + 6*22 \\
12*4 + 14*6 & 12*12 + 14*14 & 12*20 + 14*22 \\
20*4 + 22*6 & 20*12 + 22*14 & 20*20 + 22*22
\end{bmatrix}
= \begin{bmatrix}
52 & 132 & 212 \\
132 & 340 & 548 \\
212 & 548 & 884
\end{bmatrix}
$$

缩放  (除以 $\sqrt{d_k} = \sqrt{2} \approx 1.414 $：

$$
\text{Scaled Scores}_1 = \frac{1}{1.414} \begin{bmatrix}
52 & 132 & 212 \\
132 & 340 & 548 \\
212 & 548 & 884
\end{bmatrix}
\approx \begin{bmatrix}
36.77 & 93.34 & 149.91 \\
93.34 & 240.43 & 387.52 \\
149.91 & 387.52 & 625.13
\end{bmatrix}
$$

---

### **5. Softmax归一化**

对每行（每个位置的Query）进行Softmax，得到注意力权重：

#### **样本1第1行的Softmax**：

$$
\text{Softmax}([36.77, 93.34, 149.91]) \approx [0, 0, 1]
$$

（实际计算中数值会趋近于0或1，这里为简化假设极端情况）

---

### **6. 加权求和**

用注意力权重对Value向量加权求和：

#### **样本1的输出**：

$$
\text{Output}_1 = \begin{bmatrix}
0 & 0 & 1 \\
0 & 0 & 1 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
V_1^{(1)} & V_1^{(2)} & V_1^{(3)}
\end{bmatrix}
= \begin{bmatrix}
V_1^{(3)} \\
V_1^{(3)} \\
V_1^{(3)}
\end{bmatrix}
= \begin{bmatrix}
9*1 + 10*0 + 11*1 + 12*0 & 9*1 + 10*0 + 11*1 + 12*0 \\
... \\
...
\end{bmatrix}
$$

（具体数值需根据实际V计算）

---

### **7. 最终输出**

每个位置的输出是全局信息的加权组合，形状为 $ \mathbb{R}^{2 \times 3 \times 2} $，即保留了与V相同的维度。

---

### **关键点总结**

1. **维度匹配**：
   - $QK^T $ 的维度为 \( ($batch_{size}, seq_{len}, seq_{len}$) \)，表示位置间的相关性。
2. **动态权重**：
   - 权重由Query和Key的相似度动态生成，而非固定模式。
3. **并行计算**：
   - 所有位置的注意力分数可并行计算，效率远高于RNN。

通过这个三阶张量的例子，可以看到Self-Attention如何通过矩阵运算高效捕获全局依赖关系。

# 手动编写Attention层（禁止使用库函数）
